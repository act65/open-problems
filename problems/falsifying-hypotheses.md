
Imagine that we have some oracle (maybe physics for experiment design, a database for query generation, ...) that is expensive to call. Given what we )the learner) know, our next call to the oracle should be to falsify our leading hypothesis. <!-- (about ???) -->

Falsification is at the very heart of good science: generate plausible and testable hypotheses, try your hardest to prove them wrong. Keep the remaining hypotheses and repeat. 
In machine learning this process also seems to go by another name, active learning: How can you generate maximally informative queries.
