In deep learning all information is represented in finite dimensional vectors spaces, arrays. Can we generalise this to graphs (where an array is just
 a uniform grad graph)?

Why bother? Graphs allow us to represent relations, between nodes. An extra layer of information.

#### Composition

If we have two graphs representing idea __1__ and __2__, then how can we efficiently compose these to integrate their knowledge?
Trivially, we could just join where they share similar nodes? But what if we are working with nodes embedded in some real space, where it is non trivial to check similarity? Or, ?

#### Compression

What about compressing a graph?

#### Hierarchical

Sketching a graph with ? (a fixed length vector?) so we can 

Hierarchical graphs. Graphs within graphs, where a node is a graph, and the edge is ?.
  
#### Construction

How can leared systems interact with, output, read from, ... graph structures. Adjacency matrix feels hack. Want to build into computational primitives, need better libraries?



Graph signal processing?
