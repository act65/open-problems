Can we find an representation that approximates arbitrary functions easily?
Which representations can approximate type functions we care about with low error?
<!-- Does low error really matter? Does that constrain the volume of low minima?
But how easy are the minima to find?-->

What are the best algorithmic atoms to build out of?
Orthogonal ???s. Polynomials, vectors, graphs, ?,

A neural network is the combination of a few distinct ideas.

*

Why are neural networks better than SVMs, or RBFs, or ...? Are NNs best for every application?

Current wisdom hints that local and heirarchical function approximations are !!, but ?
* The ReLU is discontinuous, is that important?
