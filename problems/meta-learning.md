Aka hyper parameter optimisation?

## Learning to learn

If computers are ever going to take over the world, they will need to be able to learn to learn. This kind of self-optimisation, is what I hold dear and I believe that makes us 'intelligent'.
Learning is great, as we are currently finding out, however, there have been a few different learning algorithms over the years. First nature started out with natural selection, but it is incredibly slow O(billions of years...). Evolution then learned to be more efficient at learning, it invented malleable nervous systems to handle the faster adaptation needed to survive.

All it really means is understanding a given learning problem in more depth so we can include 'better' inductive biases in the optimiser.

* [Automated Curriculum Learning for Neural Networks](https://arxiv.org/abs/1704.03003)
* [Meta Networks](https://arxiv.org/pdf/1703.00837.pdf)
* [Learning to optimize](https://doi.org/10.3200/JMBR.36.3.339-351)
* [Learning to reinforcement learn](http://arxiv.org/abs/1611.05763)
* [Learning to learn by gradient descent by gradient descent](http://arxiv.org/abs/1606.04474)
* [Learning to learn without gradient descent by gradient descent](http://proceedings.mlr.press/v70/chen17e.htm)

## Learning to teach



Remembering memory
Optimising optimisers
